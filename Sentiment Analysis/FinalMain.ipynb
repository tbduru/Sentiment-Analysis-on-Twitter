{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa08a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAOacaQEAAAAAfief77Bv8V%2BLRCusIsMqJDdquEI%3DKEg3xZEAr2ClMqxR2RHTJRq2kn7PbkOJR5UmIu68rdA16X3hwN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83026318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk as nlp\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import neattext.functions as nfx\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter.messagebox\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "import pyttsx3 \n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd70977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilization\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "lemma=nlp.WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "def data_cleaner(tweet):\n",
    "    #     remove urls\n",
    "    tweet=re.sub(r'http\\S+', ' ',tweet)\n",
    "    \n",
    "    #     remove html tags\n",
    "    tweet=re.sub(r'<.*?>',' ',tweet)\n",
    "    \n",
    "    #     remove digits\n",
    "    tweet=re.sub(r'\\d+',' ', tweet)\n",
    "    \n",
    "    #     remove hastags\n",
    "    tweet=re.sub(r'#\\w+',' ',tweet)\n",
    "    \n",
    "    #     remove mentions\n",
    "    tweet=re.sub(r'@\\w+', ' ',tweet)\n",
    "    \n",
    "    #     remove punctions\n",
    "    tweet=re.sub('[^a-zA-Z]', ' ', tweet)\n",
    "    \n",
    "    tweet=tweet.lower()\n",
    "    tweet=nltk.word_tokenize(tweet,'english')\n",
    "    tweet=[word for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    #tweet=[stemmer.stem(word) for word in tweet]\n",
    "    tweet=[lemma.lemmatize(word) for word in tweet]\n",
    "    tweet=' '.join(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a627d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7376/3438455367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                  random_state=123)\n\u001b[0;32m     16\u001b[0m \u001b[0mtrain_upsampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_minority_upsampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_majority\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_medium\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_upsampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_upsampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m pipeline_sgd = Pipeline([\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"Corona_NLP_train.csv\",encoding=\"latin1\")[['Location','OriginalTweet','Sentiment']].head(10000)\n",
    "clean_train_df = train_df['OriginalTweet'].apply(data_cleaner)\n",
    "train_df['clean_tweet'] = clean_train_df\n",
    "# drop if clean_tweet is empty\n",
    "train_df= train_df[train_df['clean_tweet'] != 0]\n",
    "X=train_df['clean_tweet'].copy()\n",
    "y=train_df['Sentiment'].copy()\n",
    "\n",
    "train_majority = train_df[y==-1]\n",
    "train_minority = train_df[y==1]\n",
    "train_medium   = train_df[y==0]\n",
    "train_minority_upsampled = resample(train_minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=len(train_majority),\n",
    "                                 random_state=123)\n",
    "train_upsampled = pd.concat([train_minority_upsampled, train_majority,train_medium])\n",
    "label = train_upsampled['label']\n",
    "tweet = train_upsampled['clean_tweet']\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('nb', SGDClassifier()),\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweet,label,test_size = 0.5,random_state = 0)\n",
    "model = pipeline_sgd.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "mat = confusion_matrix(y_test,y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "from typing import Callable\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "def trainheatmap():\n",
    "    trainheatwin = Toplevel(master)\n",
    "    trainheatwin.configure(background='#CDCDCD')\n",
    "    def init_gui(root, update_function: Callable) -> FigureCanvasTkAgg:\n",
    "        def event_key_press(event):\n",
    "            print(\"you pressed {}\".format(event.key))\n",
    "            update_function()\n",
    "            key_press_handler(event, canvas)\n",
    "\n",
    "        # create empty figure and draw\n",
    "        init_figure = create_figure()\n",
    "        canvas = FigureCanvasTkAgg(init_figure, master=root)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "        # call key press event\n",
    "        canvas.mpl_connect(\"key_press_event\", event_key_press)\n",
    "        return canvas\n",
    "\n",
    "\n",
    "    def create_figure() -> Figure:\n",
    "        # generate some data\n",
    "        matrix = mat\n",
    "        # plot the data\n",
    "        figure = Figure(figsize=(6, 6))\n",
    "        ax = figure.subplots()\n",
    "        categories = ['Negative','Neutral','Positive']\n",
    "        sns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False, \n",
    "        xticklabels=categories, yticklabels=categories,ax=ax)\n",
    "        return figure\n",
    "\n",
    "\n",
    "    def redraw_figure():\n",
    "        figure = create_figure()\n",
    "        canvas.figure = figure\n",
    "        canvas.draw()\n",
    "\n",
    "\n",
    "    sns.set()\n",
    "    canvas = init_gui(trainheatwin, update_function=redraw_figure)\n",
    "    T = Text(trainheatwin, height = 10, width = 82)\n",
    "    T.pack()\n",
    "    T.insert(END, classification_report(y_test,y_predict))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd03533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import (\n",
    "    FigureCanvasTkAgg,\n",
    "    NavigationToolbar2Tk\n",
    ")\n",
    "def clean():\n",
    "    global df\n",
    "    clean_df = df['tweets'].apply(data_cleaner)\n",
    "    df['clean_tweet'] = clean_df \n",
    "    RER= model.predict(df.clean_tweet)\n",
    "    df['Analysis'] = RER\n",
    "    \n",
    "def downloandTweets():\n",
    "    global df\n",
    "    keyword=e1.get()\n",
    "    query = ' -is:retweet lang:en -has:images -has:videos'\n",
    "    keyword += query\n",
    "    query = keyword\n",
    "    try:\n",
    "        response = client.search_recent_tweets(query=query , max_results = 100, tweet_fields = ['lang'])\n",
    "        tweets = pd.DataFrame([tweet.text for tweet in response.data],columns=['tweets'])\n",
    "        df = tweets\n",
    "        return df     \n",
    "    except:\n",
    "        tkinter.messagebox.showinfo(\"Warning\",  \"There is no tweets with relative your keywords\")\n",
    "      \n",
    "         \n",
    "def showDownloandedTweets(df):\n",
    "    # Create an instance of tkinter frame\n",
    "    newWindow = Toplevel(master)\n",
    "    newWindow.configure(background='#CDCDCD')\n",
    "\n",
    "    # Set the geometry\n",
    "    newWindow.title(\"Downloaded Tweets\")\n",
    "    newWindow.geometry('1080x340')\n",
    "\n",
    "    # Add a text widget\n",
    "    text=ScrolledText(newWindow,wrap = WORD,width = 80,height = 10,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "\n",
    "    # Add some text in the text widget\n",
    "    \n",
    "    for i in df.tweets:\n",
    "        text.insert(END, i+\"\\n_______________________________________________________________________________\\n\")\n",
    "\n",
    "    text.pack()\n",
    "    def close_section1():\n",
    "        newWindow.destroy()\n",
    "    button1=Button(newWindow, text=\"Analyze the tweets\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[close_section1(), analyzeDTweets()])\n",
    "    button1.config( height = 3, width = 25 )\n",
    "    button1.pack(side=BOTTOM)\n",
    "    \n",
    "def analyzeDTweets():\n",
    "    clean()\n",
    "    analyzeWindow = Toplevel(master)\n",
    "    analyzeWindow.title(\"Analysing Tweets\")\n",
    "    analyzeWindow.geometry('1080x1080')\n",
    "    analyzeWindow.configure(background='#CDCDCD')\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    for i in df[\"Analysis\"]:\n",
    "        if i < 0:\n",
    "            neg+=1\n",
    "        elif i == 0:\n",
    "            neu+=1\n",
    "        else:\n",
    "            pos+=1\n",
    "    data = {\n",
    "            'Negative': neg,\n",
    "            'Neutral': neu,\n",
    "            'Positive': pos,\n",
    "        }\n",
    "    languages = data.keys()\n",
    "    popularity = data.values()\n",
    "\n",
    "        # create a figure\n",
    "    figure = Figure(figsize=(6, 4), dpi=100)\n",
    "\n",
    "        # create FigureCanvasTkAgg object\n",
    "    figure_canvas = FigureCanvasTkAgg(figure, analyzeWindow)\n",
    "\n",
    "        # create the toolbar\n",
    "    NavigationToolbar2Tk(figure_canvas, analyzeWindow)\n",
    "\n",
    "        # create axes\n",
    "    axes = figure.add_subplot()\n",
    "\n",
    "        # create the barchart\n",
    "    axes.bar(languages, popularity)\n",
    "    axes.set_title('3 Label in Downloaded Tweets')\n",
    "    axes.set_ylabel('Sentiment')\n",
    "\n",
    "\n",
    "    figure_canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "    button1=Button(analyzeWindow, text=\"Word in Specific Label\",background='#CDCDCD',\n",
    "                   font=('arial',15,'bold'),fg=\"black\",\n",
    "                   command=wordInLabel)\n",
    "    button1.config( height = 3, width = 25 )\n",
    "    button1.pack()\n",
    "\n",
    "def wordInLabel():\n",
    "    wordLabel = Toplevel(master)\n",
    "    wordLabel.title(\"Detail Tweets\")\n",
    "    wordLabel.geometry('648x340')\n",
    "    wordLabel.configure(background='#CDCDCD')\n",
    "    button1=Button(wordLabel, text=\"Back of Negative Words\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(-1)])\n",
    "    button2=Button(wordLabel, text=\"Back of Neutral  Words\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(0)])\n",
    "    button3=Button(wordLabel, text=\"Back of Positive Words\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(1)])\n",
    "    button11=Button(wordLabel, text=\" Negative Tweets\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(11)])\n",
    "    button22=Button(wordLabel, text=\"  Neutral Tweets\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(22)])\n",
    "    button33=Button(wordLabel, text=\" Positive Tweets\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(33)])\n",
    "    button4=Button(wordLabel, text=\" Top 10 Hashtag\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[chooce(2)])\n",
    "    button1.grid(row=0,column=1)\n",
    "    button2.grid(row=1,column=1)\n",
    "    button3.grid(row=2,column=1)\n",
    "    button11.grid(row=0,column=2)\n",
    "    button22.grid(row=1,column=2)\n",
    "    button33.grid(row=2,column=2)\n",
    "    button4.grid(row=1,column=3)\n",
    "    all_words = \"\"\n",
    "    def chooce(n):\n",
    "        if n < 0 :\n",
    "            all_words = \" \".join([sentence for sentence in df['clean_tweet'][df['Analysis']==-1]])\n",
    "            wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(all_words)    \n",
    "            plt.figure(figsize=(15,8))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        if n == 0:\n",
    "            all_words = \" \".join([sentence for sentence in df['clean_tweet'][df['Analysis']==0]])\n",
    "            wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(all_words)    \n",
    "            plt.figure(figsize=(15,8))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        if n == 1:\n",
    "            all_words = \" \".join([sentence for sentence in df['clean_tweet'][df['Analysis']==1]])\n",
    "            wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(all_words)    \n",
    "            plt.figure(figsize=(15,8))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        if n == 11:\n",
    "            words = Toplevel(wordLabel)\n",
    "            words.title(\"Negative Tweets\")\n",
    "            words.geometry('1080x340')\n",
    "            label_sepetereter= Label(words,text=\"Negative Tweets\",font=('Courier New',20),fg=\"black\")\n",
    "            text=ScrolledText(words,wrap = WORD,width = 80,height = 10,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "            for i in df['tweets'][df['Analysis']==-1]:\n",
    "                text.insert(END, i+\"\\n_______________________________________________________________________________\\n\")\n",
    "            label_sepetereter.pack()\n",
    "            text.pack()\n",
    "        if n == 22:\n",
    "            words = Toplevel(wordLabel)\n",
    "            words.title(\"Neutral Tweets\")\n",
    "            words.geometry('1080x340')\n",
    "            label_sepetereter= Label(words,text=\"Neutral Tweets\",font=('Courier New',20),fg=\"black\")\n",
    "            text=ScrolledText(words,wrap = WORD,width = 80,height = 10,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "            for i in df['tweets'][df['Analysis']==0]:\n",
    "                text.insert(END, i+\"\\n_______________________________________________________________________________\\n\")\n",
    "            label_sepetereter.pack()\n",
    "            text.pack()\n",
    "        if n == 33:\n",
    "            words = Toplevel(wordLabel)\n",
    "            words.title(\"Positive Tweets\")\n",
    "            words.geometry('1080x340')\n",
    "            label_sepetereter= Label(words,text=\"Positive Tweets\",font=('Courier New',20),fg=\"black\")\n",
    "            text=ScrolledText(words,wrap = WORD,width = 80,height = 10,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "            for i in df['tweets'][df['Analysis']==1]:\n",
    "                text.insert(END, i+\"\\n_______________________________________________________________________________\\n\")\n",
    "            label_sepetereter.pack()\n",
    "            text.pack()\n",
    "        if n == 2:\n",
    "            extract_hashtags =df['tweets'].apply(nfx.extract_hashtags)\n",
    "            extract_hashtags = sum(extract_hashtags, [])\n",
    "            freq = nltk.FreqDist(extract_hashtags)\n",
    "            d = pd.DataFrame({'Hashtag': list(freq.keys()),'Count': list(freq.values())})\n",
    "            d = d.nlargest(columns='Count', n=10)\n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.title('Top 10 Hashtags',fontsize=15)\n",
    "            plt.xticks(rotation=45)\n",
    "            sns.barplot(data=d, x='Hashtag', y='Count')\n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_button():\n",
    "    label_2.config(text = \"Press for Downloanding\")\n",
    "    btn1.configure(text = \"Download\" ,command=lambda:[downloandTweets, show_button()])\n",
    "    \n",
    "def show_button():\n",
    "    label_2.config(text = \" Press for Showing\")\n",
    "    if len(e1.get()) != 0:\n",
    "        df = downloandTweets()\n",
    "        btn1.configure(text = \"show\", command=lambda:[showDownloandedTweets(df), reset_button()])\n",
    "    else:\n",
    "        tkinter.messagebox.showinfo(\"Warning\",  \"Please enter keyword\")\n",
    "#MAIN\n",
    "master = Tk() \n",
    "master.title(\"Sentiment Analysis On Twitter\")\n",
    "master.geometry('750x200')\n",
    "master.configure(background='#CDCDCD')\n",
    "\n",
    "label_1 = Label(master, text='Keyword:',background='#CDCDCD', font=('arial',15,'bold')).grid(row=0,column=0) \n",
    "e1 = Entry(master,bd =10,width=30,font=20) \n",
    "e1.grid(row=0, column=5) \n",
    "label_2 = Label(master,text=\"Press for Downloanding\",background='#CDCDCD', font=('arial',15,'bold'))\n",
    "label_3 = Label(master,text=\"Click for showing trained data\",background='#CDCDCD', font=('arial',15,'bold'))\n",
    "label_sepetereter= Label(master,text=\"_____________________\",font=('Courier New',20),bg=\"blue\",fg=\"blue\")\n",
    "    \n",
    "\n",
    "btn1=Button(master,text=\" Download \",bg=\"blue\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=lambda:[downloandTweets, show_button()])#command=lambda:[function1(), function2()]\n",
    "btn2=Button(master,text=\"Click\",bg=\"blue\",background='#CDCDCD', font=('arial',15,'bold'),fg=\"black\",command=trainheatmap)\n",
    "label_2.grid(row=2,column=0)\n",
    "label_3.grid(row=4,column=0)\n",
    "label_sepetereter.grid(row=3,column=0)\n",
    "btn1.grid(row=2,column=5)\n",
    "btn2.grid(row=4,column=5)\n",
    "\n",
    "\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b77e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
